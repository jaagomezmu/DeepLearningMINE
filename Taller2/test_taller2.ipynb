{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06f628df-c824-4a8b-b71f-6867dc3b3694",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import random\n",
    "import time\n",
    "import shutil\n",
    "import zipfile\n",
    "\n",
    "import kaggle\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import tensorflow as tf\n",
    "from ultralytics import YOLO\n",
    "\n",
    "random_state = random.randint(1,999)\n",
    "display(random_state)\n",
    "\n",
    "# COnfiguraciones para tensorflow\n",
    "os.environ['TF_ENABLE_ONEDNN_OPTS'] = '0'\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab5523dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "! cat /root/.config/Ultralytics/settings.json\n",
    "! sed -i 's|\"datasets_dir\":.*|\"datasets_dir\": \"/app\",|' /root/.config/Ultralytics/settings.json\n",
    "! cat /root/.config/Ultralytics/settings.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8562b1a3-21b0-4e95-a8b3-78c54aa8cf80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download data from kaggle\n",
    "\n",
    "RAW_DATA_ZIP = \"data/raw/data2/rsud20k-bangladesh-road-scene-understanding.zip\"\n",
    "EXTRACTED_DATA = \"data/preprocessed/data2\"\n",
    "\n",
    "dataset = \"hasibzunair/rsud20k-bangladesh-road-scene-understanding\"\n",
    "kaggle.api.dataset_download_files(dataset, path='data/raw/data2')\n",
    "\n",
    "with zipfile.ZipFile(RAW_DATA_ZIP, 'r') as zip_ref:\n",
    "        zip_ref.extractall(EXTRACTED_DATA)\n",
    "        print(f\"Extracted all files to {EXTRACTED_DATA}\")\n",
    "\n",
    "DATA_DIR = Path(\"data/preprocessed/data2/rsud20k\")\n",
    "DATA_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "250477fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_and_validate_paths(data_dir):\n",
    "    subdirs = ['images', 'labels']\n",
    "    categories = ['test', 'train', 'val']\n",
    "    folder_dict = {}\n",
    "\n",
    "    print(\"Printing folder paths and checking their validity:\")\n",
    "    for subdir in subdirs:\n",
    "        for category in categories:\n",
    "            folder_name = f\"{subdir}_{category}\"\n",
    "            folder_path = data_dir / subdir / category\n",
    "            folder_dict[folder_name] = folder_path\n",
    "            print(f\"{folder_name}: {folder_path}\")\n",
    "            print(f\"Is the path valid?: {folder_path.exists()}\")\n",
    "\n",
    "    return folder_dict\n",
    "\n",
    "folder_dict = generate_and_validate_paths(DATA_DIR)\n",
    "folder_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1ff96888",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_image_paths(data_dir):\n",
    "    subdirs = ['images']\n",
    "    data_dir = Path(data_dir)\n",
    "    images_folder = data_dir / subdirs[0]\n",
    "    categories = ['test', 'train', 'val']\n",
    "    folder_paths = [images_folder / category for category in categories]\n",
    "    train_folder = images_folder / 'train'\n",
    "    train_images = list(train_folder.glob('*'))\n",
    "    return folder_paths, train_images\n",
    "\n",
    "def process_image_folders(folder_list, img_ext):\n",
    "    img_name_list = []\n",
    "    img_width_list = []\n",
    "    img_height_list = []\n",
    "    img_folder_list = []\n",
    "    img_format_list = []\n",
    "\n",
    "    for folder in folder_list:\n",
    "        parent_name = folder.name\n",
    "        for img_path in folder.iterdir():\n",
    "            if img_path.is_file():\n",
    "                img_folder_list.append(parent_name)\n",
    "                img_name_list.append(img_path.name)\n",
    "\n",
    "                img_format = img_path.suffix.lower()\n",
    "                img_format_list.append(\n",
    "                    \"ok\" if img_format in img_ext else \"not ok\")\n",
    "\n",
    "                with Image.open(img_path) as img:\n",
    "                    width, height = img.size\n",
    "                    img_width_list.append(width)\n",
    "                    img_height_list.append(height)\n",
    "\n",
    "    data_model = {\n",
    "        \"folder\": img_folder_list,\n",
    "        \"image_name\": img_name_list,\n",
    "        \"width\": img_width_list,\n",
    "        \"height\": img_height_list,\n",
    "        \"format\": img_format_list\n",
    "    }\n",
    "\n",
    "    return pd.DataFrame(data=data_model)\n",
    "\n",
    "IMAGE_EXT = {'.jpg', '.jpeg', '.png'}\n",
    "LABEL_EXT = {'.txt'}\n",
    "folder_list, train_images = generate_image_paths(DATA_DIR)\n",
    "report_df = process_image_folders(folder_list, IMAGE_EXT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb5b1805",
   "metadata": {},
   "outputs": [],
   "source": [
    "report_df_group = report_df.groupby(\n",
    "    ['folder', 'format', 'width', 'height']).count()\n",
    "report_df_group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c882e37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shuffle train images\n",
    "random.shuffle(train_images)\n",
    "selected_images = train_images[:9]\n",
    "\n",
    "print(\"Selected image paths after shuffle:\")\n",
    "for img in selected_images:\n",
    "    print(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3e9225b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_ima_matrix(image_list, show_axis=False):\n",
    "    MAX_SIZE = 9\n",
    "    if len(image_list) != MAX_SIZE:\n",
    "        raise(f\"Se requieren exactamente {MAX_SIZE} imágenes para crear la matriz.\")\n",
    "\n",
    "    plt.figure(figsize=(15, 10))\n",
    "    gs1 = gridspec.GridSpec(3, 3)\n",
    "    gs1.update(wspace=0.15, hspace=0.005)\n",
    "    for i in range(MAX_SIZE):\n",
    "        ima_file = image_list[i]\n",
    "        ima_name = os.path.basename(ima_file)\n",
    "        ax = plt.subplot(gs1[i])\n",
    "        plt.imshow(np.array(Image.open(ima_file)))\n",
    "        plt.title(ima_name[:20])\n",
    "        plt.axis(\"on\" if show_axis else \"off\")\n",
    "    plt.show()\n",
    "show_ima_matrix(selected_images, show_axis=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8104f453",
   "metadata": {},
   "outputs": [],
   "source": [
    "def verify_alignment(folder_dict):\n",
    "    \"\"\"\n",
    "    Verifies alignment between images and corresponding label files.\n",
    "\n",
    "    Args:\n",
    "        folder_dict (dict): Dictionary containing image and label folder paths.\n",
    "\n",
    "    Returns:\n",
    "        None: Prints images without labels and labels without images for each folder.\n",
    "    \"\"\"\n",
    "    categories = ['train', 'test', 'val']\n",
    "    \n",
    "    for category in categories:\n",
    "        img_folder = folder_dict[f'images_{category}']\n",
    "        lbl_folder = folder_dict[f'labels_{category}']\n",
    "        \n",
    "        img_files = {f.stem for f in img_folder.iterdir() if f.suffix.lower() in IMAGE_EXT}\n",
    "        lbl_files = {f.stem for f in lbl_folder.iterdir() if f.suffix.lower() in LABEL_EXT}\n",
    "\n",
    "        imgs_without_labels = img_files - lbl_files\n",
    "        if imgs_without_labels:\n",
    "            print(f\"Imágenes sin etiquetas en la carpeta {img_folder}: {', '.join(imgs_without_labels)}\")\n",
    "\n",
    "        labels_without_imgs = lbl_files - img_files\n",
    "        if labels_without_imgs:\n",
    "            print(f\"Etiquetas sin imágenes en la carpeta {lbl_folder}: {', '.join(labels_without_imgs)}\")\n",
    "\n",
    "verify_alignment(folder_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "4d3fb618",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_datasets(folder_dict, batch_size=4, image_size=(640, 640), sample_size=0.1):\n",
    "    \"\"\"\n",
    "    Creates TensorFlow datasets for training, validation, and test with streaming data loading,\n",
    "    and also samples a subset of the dataset into new folders.\n",
    "\n",
    "    Args:\n",
    "        folder_dict (dict): Dictionary containing folder paths for images and labels.\n",
    "        batch_size (int): Size of the data batches for training, validation, and test.\n",
    "        image_size (tuple): Size to which images will be resized (height, width).\n",
    "        sample_size (float): Percentage of the dataset to sample and move to new folders.\n",
    "\n",
    "    Returns:\n",
    "        train_dataset (tf.data.Dataset): Streaming dataset for training.\n",
    "        val_dataset (tf.data.Dataset): Streaming dataset for validation.\n",
    "        test_dataset (tf.data.Dataset): Streaming dataset for test.\n",
    "    \"\"\"\n",
    "\n",
    "    def create_image_and_label_paths(image_folder, label_folder):\n",
    "        \"\"\"\n",
    "        Generates lists of image paths and corresponding label paths.\n",
    "\n",
    "        Args:\n",
    "            image_folder (Path): Folder containing images.\n",
    "            label_folder (Path): Folder containing labels.\n",
    "\n",
    "        Returns:\n",
    "            image_paths (list): List of image paths.\n",
    "            label_paths (list): List of corresponding label paths.\n",
    "        \"\"\"\n",
    "        image_paths = sorted(list(image_folder.glob('*.jpg')))\n",
    "        label_paths = [label_folder / img_path.with_suffix('.txt').name for img_path in image_paths]\n",
    "        return image_paths, label_paths\n",
    "\n",
    "    def load_image_and_label(image_path, label_path):\n",
    "        \"\"\"\n",
    "        Loads an image and its corresponding label.\n",
    "\n",
    "        Args:\n",
    "            image_path (str): Path to the image.\n",
    "            label_path (str): Path to the label.\n",
    "\n",
    "        Returns:\n",
    "            image (tensor): Resized and normalized image.\n",
    "            label (tensor): Label as a tensor.\n",
    "        \"\"\"\n",
    "        image = tf.io.read_file(image_path)\n",
    "        image = tf.image.decode_jpeg(image, channels=3)\n",
    "        image = tf.image.resize(image, image_size)\n",
    "        image = image / 255.0\n",
    "\n",
    "        label = tf.io.read_file(label_path)\n",
    "        label = tf.strings.strip(label)\n",
    "        label = tf.strings.split(label, '\\n')\n",
    "\n",
    "        label = tf.strings.split(label)\n",
    "        label = tf.strings.to_number(label, out_type=tf.float32)\n",
    "\n",
    "        return image, label\n",
    "\n",
    "    def image_label_generator(image_paths, label_paths):\n",
    "        \"\"\"\n",
    "        Generates image-label pairs in streaming mode.\n",
    "\n",
    "        Args:\n",
    "            image_paths (list): List of image paths.\n",
    "            label_paths (list): List of corresponding label paths.\n",
    "\n",
    "        Yields:\n",
    "            image (tensor): Resized and normalized image.\n",
    "            label (tensor): Label as a tensor.\n",
    "        \"\"\"\n",
    "        for img_path, lbl_path in zip(image_paths, label_paths):\n",
    "            yield str(img_path), str(lbl_path)  # Convert paths to strings\n",
    "\n",
    "    def create_sampled_folders(sampled_image_paths, sampled_label_paths, sample_folder):\n",
    "        \"\"\"\n",
    "        Creates new folders for sampled images and labels and moves files into them.\n",
    "\n",
    "        Args:\n",
    "            sampled_image_paths (list): List of sampled image paths.\n",
    "            sampled_label_paths (list): List of corresponding sampled label paths.\n",
    "            sample_folder (Path): Destination folder for the sampled data.\n",
    "        \"\"\"\n",
    "        image_folder = sample_folder / \"images\"\n",
    "        label_folder = sample_folder / \"labels\"\n",
    "        os.makedirs(image_folder, exist_ok=True)\n",
    "        os.makedirs(label_folder, exist_ok=True)\n",
    "\n",
    "        for img_path, lbl_path in zip(sampled_image_paths, sampled_label_paths):\n",
    "            # Load and transform the image\n",
    "            image = tf.io.read_file(str(img_path))  # Ensure to convert to string\n",
    "            image = tf.image.decode_jpeg(image, channels=3)\n",
    "            image = tf.image.resize(image, image_size)\n",
    "            image = image / 255.0\n",
    "\n",
    "            # Save the transformed image\n",
    "            transformed_image_path = image_folder / img_path.name\n",
    "            tf.io.write_file(str(transformed_image_path), tf.image.encode_jpeg(tf.cast(image * 255, tf.uint8)))\n",
    "\n",
    "            # Copy the label file\n",
    "            shutil.copy(str(lbl_path), label_folder / lbl_path.name)  # Ensure to convert to string\n",
    "\n",
    "        print(f\"Sampled images saved to: {image_folder}\")\n",
    "        print(f\"Sampled labels saved to: {label_folder}\")\n",
    "\n",
    "    # Paths for train, validation, and test datasets\n",
    "    train_image_paths, train_label_paths = create_image_and_label_paths(\n",
    "        folder_dict['images_train'], folder_dict['labels_train']\n",
    "    )\n",
    "    \n",
    "    val_image_paths, val_label_paths = create_image_and_label_paths(\n",
    "        folder_dict['images_val'], folder_dict['labels_val']\n",
    "    )\n",
    "    \n",
    "    test_image_paths, test_label_paths = create_image_and_label_paths(\n",
    "        folder_dict['images_test'], folder_dict['labels_test']\n",
    "    )\n",
    "\n",
    "    # Sample: select a percentage of the training, validation, and test sets\n",
    "    total_train_samples = len(train_image_paths)\n",
    "    sample_size_count = int(total_train_samples * sample_size)\n",
    "    \n",
    "    sampled_train_image_paths = train_image_paths[:sample_size_count]\n",
    "    sampled_train_label_paths = train_label_paths[:sample_size_count]\n",
    "\n",
    "    # Create new sampled folders for train, val, and test\n",
    "    sample_train_folder = Path(\"data/sample/train\")\n",
    "    sample_val_folder = Path(\"data/sample/val\")\n",
    "    sample_test_folder = Path(\"data/sample/test\")\n",
    "\n",
    "    create_sampled_folders(sampled_train_image_paths, sampled_train_label_paths, sample_train_folder)\n",
    "    create_sampled_folders(val_image_paths, val_label_paths, sample_val_folder)\n",
    "    create_sampled_folders(test_image_paths, test_label_paths, sample_test_folder)\n",
    "\n",
    "    # Streaming datasets (for TensorFlow training)\n",
    "    train_dataset = tf.data.Dataset.from_generator(\n",
    "        lambda: image_label_generator(sampled_train_image_paths, sampled_train_label_paths),\n",
    "        output_signature=(\n",
    "            tf.TensorSpec(shape=(), dtype=tf.string),\n",
    "            tf.TensorSpec(shape=(), dtype=tf.string)\n",
    "        )\n",
    "    )\n",
    "    train_dataset = train_dataset.map(\n",
    "        lambda img, lbl: load_image_and_label(img, lbl), num_parallel_calls=tf.data.AUTOTUNE\n",
    "    )\n",
    "    train_dataset = train_dataset.batch(batch_size).prefetch(buffer_size=tf.data.AUTOTUNE)\n",
    "\n",
    "    val_dataset = tf.data.Dataset.from_generator(\n",
    "        lambda: image_label_generator(val_image_paths, val_label_paths),\n",
    "        output_signature=(\n",
    "            tf.TensorSpec(shape=(), dtype=tf.string),\n",
    "            tf.TensorSpec(shape=(), dtype=tf.string)\n",
    "        )\n",
    "    )\n",
    "    val_dataset = val_dataset.map(\n",
    "        lambda img, lbl: load_image_and_label(img, lbl), num_parallel_calls=tf.data.AUTOTUNE\n",
    "    )\n",
    "    val_dataset = val_dataset.batch(batch_size).prefetch(buffer_size=tf.data.AUTOTUNE)\n",
    "\n",
    "    test_dataset = tf.data.Dataset.from_generator(\n",
    "        lambda: image_label_generator(test_image_paths, test_label_paths),\n",
    "        output_signature=(\n",
    "            tf.TensorSpec(shape=(), dtype=tf.string),\n",
    "            tf.TensorSpec(shape=(), dtype=tf.string)\n",
    "        )\n",
    "    )\n",
    "    test_dataset = test_dataset.map(\n",
    "        lambda img, lbl: load_image_and_label(img, lbl), num_parallel_calls=tf.data.AUTOTUNE\n",
    "    )\n",
    "    test_dataset = test_dataset.batch(batch_size).prefetch(buffer_size=tf.data.AUTOTUNE)\n",
    "\n",
    "    return train_dataset, val_dataset, test_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ea29f2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset, val_dataset, test_dataset = create_datasets(\n",
    "    folder_dict,\n",
    "    image_size=(640, 640),\n",
    "    sample_size=0.2,\n",
    "    # sample_val_test=False\n",
    ")\n",
    "\n",
    "# Verify\n",
    "for image, label in train_dataset.take(1):\n",
    "    print(\"Image shape:\", image.numpy().shape)\n",
    "    print(\"Label:\", label.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "431450a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_dict_sample = {\n",
    "    'images_test': Path('data/sample/test/images'),\n",
    "    'images_train': Path('data/sample/train/images'),\n",
    "    'images_val': Path('data/sample/val/images'),\n",
    "    'labels_test': Path('data/sample/test/labels'),\n",
    "    'labels_train': Path('data/sample/train/labels'),\n",
    "    'labels_val': Path('data/sample/val/labels')\n",
    "}\n",
    "verify_alignment(folder_dict_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66e67f35",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_list2 = list(folder_dict_sample.get(\"images_train\").glob(\"*.jpg\"))[:9]\n",
    "random.shuffle(image_list2)\n",
    "print(\"Selected image paths after shuffle:\")\n",
    "for img in image_list2:\n",
    "    print(img)\n",
    "show_ima_matrix(image_list2, show_axis=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59f758ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "yaml_content = f\"\"\"\n",
    "\n",
    "train: sample/train/images\n",
    "val: sample/val/images\n",
    "test: sample/test/images\n",
    "\n",
    "train_labels: sample/train/labels\n",
    "val_labels: sample/val/labels\n",
    "test_labels: sample/test/labels\n",
    "\n",
    "# Clases que el modelo debe detectar\n",
    "names:\n",
    "  0: person\n",
    "  1: rickshaw\n",
    "  2: rickshaw van\n",
    "  3: auto rickshaw\n",
    "  4: truck\n",
    "  5: pickup truck\n",
    "  6: private car\n",
    "  7: motorcycle\n",
    "  8: bicycle\n",
    "  9: bus\n",
    "  10: micro bus\n",
    "  11: covered van\n",
    "  12: human hauler\n",
    "\"\"\"\n",
    "\n",
    "with open('data/settings_no_tuned.yaml', 'w') as file:\n",
    "    file.write(yaml_content)\n",
    "\n",
    "! cat data/settings_no_tuned.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c83ba5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "YOLO_VERSION = 'yolov8m.pt'\n",
    "model = YOLO(f'{YOLO_VERSION}')\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "model.train(\n",
    "    data='data/settings_no_tuned.yaml',\n",
    "    epochs=15,\n",
    "    imgsz=640,\n",
    "    batch=4,\n",
    "    lr0=0.01,\n",
    ")\n",
    "\n",
    "end_time = time.time()\n",
    "elapsed_time = end_time - start_time\n",
    "print(f\"Tiempo total de entrenamiento: {elapsed_time:.2f} segundos\")\n",
    "\n",
    "metrics = model.val(data='data/settings_no_tuned.yaml')\n",
    "print(metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7de091fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "yaml_content = f\"\"\"\n",
    "# Ruta raíz de las imágenes y etiquetas\n",
    "train: preprocessed/data2/rsud20k/images/train   # Ruta a las imágenes de entrenamiento\n",
    "val: preprocessed/data2/rsud20k/images/val       # Ruta a las imágenes de validación\n",
    "test: preprocessed/data2/rsud20k/images/test     # Ruta a las imágenes de prueba (opcional)\n",
    "\n",
    "# Rutas a las etiquetas (opcional si se necesita)\n",
    "train_labels: preprocessed/data2/rsud20k/labels/train   # Ruta a las etiquetas de entrenamiento\n",
    "val_labels: preprocessed/data2/rsud20k/labels/val       # Ruta a las etiquetas de validación\n",
    "test_labels: preprocessed/data2/rsud20k/labels/test     # Ruta a las etiquetas de prueba (opcional)\n",
    "\n",
    "# Clases que el modelo debe detectar\n",
    "names:\n",
    "  0: person\n",
    "  1: rickshaw\n",
    "  2: rickshaw van\n",
    "  3: auto rickshaw\n",
    "  4: truck\n",
    "  5: pickup truck\n",
    "  6: private car\n",
    "  7: motorcycle\n",
    "  8: bicycle\n",
    "  9: bus\n",
    "  10: micro bus\n",
    "  11: covered van\n",
    "  12: human hauler\n",
    "\n",
    "batch_size: 4\n",
    "workers: 4\n",
    "\"\"\"\n",
    "\n",
    "with open('data/settings_tuned.yaml', 'w') as file:\n",
    "    file.write(yaml_content)\n",
    "\n",
    "! cat data/settings_tuned.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aabb89f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
